{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Snigdha\\Documents\\ADS\\Raw_Data\n",
      "0\n",
      "C:\\Users\\Snigdha\\Documents\\ADS\\Raw_Data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Snigdha\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2717: DtypeWarning: Columns (8,10,11,14,15,19,20,22,23,25,38) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n",
      "C:\\Users\\Snigdha\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2717: DtypeWarning: Columns (8,10,11,14,15,18,20,22,23,25,38) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n",
      "C:\\Users\\Snigdha\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2717: DtypeWarning: Columns (8,10,11,12,13,14,15,16,17,20,23,25,37,38,39,40,44,45,46,47,49,50,59,61,62,63,64,68,84,85,86,87) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "first argument must be an iterable of pandas objects, you passed an object of type \"DataFrame\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-593e27828e9c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mindex_col\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0mframe\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mframe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m     \u001b[0mframe1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m     \u001b[0minitialfile\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"PA_\"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'{:%d%m%y}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0md\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"_WBAN_14737.csv\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0mframe1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minitialfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Snigdha\\Anaconda3\\lib\\site-packages\\pandas\\tools\\merge.py\u001b[0m in \u001b[0;36mconcat\u001b[0;34m(objs, axis, join, join_axes, ignore_index, keys, levels, names, verify_integrity, copy)\u001b[0m\n\u001b[1;32m   1449\u001b[0m                        \u001b[0mkeys\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnames\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnames\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1450\u001b[0m                        \u001b[0mverify_integrity\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverify_integrity\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1451\u001b[0;31m                        copy=copy)\n\u001b[0m\u001b[1;32m   1452\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1453\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Snigdha\\Anaconda3\\lib\\site-packages\\pandas\\tools\\merge.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, objs, axis, join, join_axes, keys, levels, names, ignore_index, verify_integrity, copy)\u001b[0m\n\u001b[1;32m   1464\u001b[0m             raise TypeError('first argument must be an iterable of pandas '\n\u001b[1;32m   1465\u001b[0m                             \u001b[1;34m'objects, you passed an object of type '\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1466\u001b[0;31m                             '\"{0}\"'.format(type(objs).__name__))\n\u001b[0m\u001b[1;32m   1467\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1468\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mjoin\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'outer'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: first argument must be an iterable of pandas objects, you passed an object of type \"DataFrame\""
     ]
    }
   ],
   "source": [
    "# coding: utf-8\n",
    "\n",
    "# In[1]:\n",
    "\n",
    "import json\n",
    "import urllib.request\n",
    "import boto3\n",
    "from botocore.client import Config\n",
    "import datetime as dt\n",
    "import arrow\n",
    "import pandas as pd\n",
    "import glob\n",
    "import logging\n",
    "import os\n",
    "\n",
    "cwd = os.getcwd()\n",
    "print(cwd)\n",
    "\n",
    "d = dt.date.today()\n",
    "p1 = cwd + '/Initial_csv'\n",
    "p2 = cwd + '/New_data'\n",
    "\n",
    "if not os.path.exists(p1):\n",
    "    os.mkdir('Initial_csv')\n",
    "if not os.path.exists(p2):\n",
    "    os.mkdir('New_data')\n",
    "\n",
    "logfile = 'logger.log'\n",
    "\n",
    "logging.basicConfig(format='%(asctime)s %(message)s', datefmt='%m/%d/%Y %I:%M:%S %p',filename=logfile,level=logging.INFO)\n",
    "\n",
    "#Create a connection\n",
    "s3 = boto3.resource('s3',\n",
    "                    aws_access_key_id = 'AKIAJ4QTMNOISHOADXPA' , \n",
    "                    aws_secret_access_key =  '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' , \n",
    "                    config = Config(signature_version='s3v4')\n",
    "                   )\n",
    "#boto3.set_stream_logger('boto3.resources', logging.INFO)\n",
    "#Create a bucket\n",
    "logging.info('Connection created')\n",
    "#s3.create_bucket(Bucket='team7_pa_assignment1')\n",
    "logging.info('Bucket created')\n",
    "bucket = s3.Bucket('team7_pa_assignment1')  \n",
    "bucketlen = len(list(bucket.objects.all()))\n",
    "print(bucketlen)\n",
    "if bucketlen == 0 :\n",
    "    print(cwd)\n",
    "    #initial data uploading get files from configinitial\n",
    "    with open('configinitial.json') as json_data_file:\n",
    "        data = json.load(json_data_file)\n",
    "        for i in data[\"result\"]:\n",
    "            url = i[\"link\"]\n",
    "            fname = url[37:]\n",
    "            os.chdir(p1)\n",
    "            cwd1 = os.getcwd()\n",
    "            urllib.request.urlretrieve(url, fname)\n",
    "    \n",
    "#initial data uploading get merge csv  \n",
    "    allFiles = glob.glob(cwd1 + \"\\*.csv\")\n",
    "    frame = pd.DataFrame([])\n",
    "    for file_ in allFiles:\n",
    "        df = pd.read_csv(file_,index_col=False, header=0)\n",
    "        frame = frame.append(df)\n",
    "    initialfile = \"PA_\" + '{:%d%m%y}'.format(d) + \"_WBAN_14737.csv\"\n",
    "    frame.to_csv(initialfile, index=False)\n",
    "    #upload initial data\n",
    "    data1 = open(initialfile, 'rb')\n",
    "    s3.Bucket('team7_pa_assignment1').put_object(Key=initialfile, Body=data1)\n",
    "    logging.info('Bucket empty: Initial data uploaded')    \n",
    "   \n",
    "    \n",
    "else:   \n",
    "\n",
    "    os.chdir(cwd)\n",
    "    d = dt.date.today()\n",
    "    print(d)\n",
    "    #upload latest data\n",
    "    with open('config.json') as json_data_file:\n",
    "        data = json.load(json_data_file)\n",
    "    url = data['link']\n",
    "    os.chdir(p2)\n",
    "    #get data from config file\n",
    "    urllib.request.urlretrieve(url, 'configfiledata.csv')\n",
    "    logging.info('Data downloaded fron config file path')\n",
    "\n",
    "    df2 = pd.read_csv('configfiledata.csv',index_col=False, header=0)\n",
    "    #download latest file from bucket\n",
    "\n",
    "    b = list(bucket.objects.all())\n",
    "    l = [(k, k.last_modified) for k in b]\n",
    "    l1 = [k for k, v in sorted(l, key=lambda p: p[1], reverse=True)]\n",
    "    key_to_download = l1[0].key\n",
    "\n",
    "    s3.Bucket('team7_pa_assignment1').download_file(key_to_download, key_to_download)\n",
    "    df1 = pd.read_csv(key_to_download,index_col=False, header=0)\n",
    "    logging.info('Latest Data From bucket downloaded')\n",
    "    df3 = df1.append(df2)\n",
    "\n",
    "\n",
    "    #upload latest data\n",
    "    newfile = 'PA_' +'{:%d%m%y}'.format(d) +'_WBAN_14737.csv'\n",
    "    df3.to_csv(newfile, index=False)\n",
    "    key = newfile\n",
    "    objs = list(bucket.objects.filter(Prefix=key))\n",
    "    if len(objs) > 0 and objs[0].key == key:\n",
    "        print(\"File already exists in your bucket!!\")\n",
    "        logging.error('File already exists in your bucket!!Please remove duplicate file.')\n",
    "    else:\n",
    "        data2 = open(newfile, 'rb')\n",
    "        s3.Bucket('team7_pa_assignment1').put_object(Key=newfile, Body=data2)\n",
    "        logging.info('New file uploaded')\n",
    "os.chdir(cwd)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# coding: utf-8\n",
    "\n",
    "# In[1]:\n",
    "\n",
    "import json\n",
    "import urllib.request\n",
    "import boto3\n",
    "from botocore.client import Config\n",
    "import datetime as dt\n",
    "import arrow\n",
    "import pandas as pd\n",
    "import glob\n",
    "import logging\n",
    "import os\n",
    "\n",
    "cwd = os.getcwd()\n",
    "print(cwd)\n",
    "\n",
    "\n",
    "d = dt.date.today()\n",
    "p1 = cwd + '/Initial_csv'\n",
    "p2 = cwd + '/Newdata'\n",
    "\n",
    "if not os.path.exists(p1):\n",
    "    os.mkdir('Initial_csv')\n",
    "if not os.path.exists(p2):\n",
    "    os.mkdir('Newdata')\n",
    "\n",
    "logfile = 'logger.log'\n",
    "\n",
    "logging.basicConfig(format='%(asctime)s %(message)s', datefmt='%m/%d/%Y %I:%M:%S %p',filename=logfile,level=logging.INFO)\n",
    "\n",
    "with open('config.json') as json_data_file:\n",
    "    data = json.load(json_data_file)\n",
    "    accesskey = data['AWSAccess']\n",
    "    secretkey = data['secretkey']\n",
    "    \n",
    "#Create a connection\n",
    "s3 = boto3.resource('s3',\n",
    "                    aws_access_key_id =  accesskey, \n",
    "                    aws_secret_access_key =  secretkey , \n",
    "                    config = Config(signature_version='s3v4')\n",
    "                   )\n",
    "#boto3.set_stream_logger('boto3.resources', logging.INFO)\n",
    "#Create a bucket\n",
    "#logging.info('Connection created')\n",
    "#s3.create_bucket(Bucket='team7pa_assignment1')\n",
    "logging.info('Bucket created')\n",
    "bucket = s3.Bucket('team7pa_assignment1')  \n",
    "bucketlen = len(list(bucket.objects.all()))\n",
    "print(bucketlen)\n",
    "if bucketlen == 0 :\n",
    "    print(cwd)\n",
    "    #initial data uploading get files from configinitial\n",
    "    with open('configinitial.json') as json_data_file:\n",
    "        data = json.load(json_data_file)\n",
    "        for i in data[\"result\"]:\n",
    "            url = i[\"link\"]\n",
    "            fname = url[37:]\n",
    "            os.chdir(p1)\n",
    "            cwd1 = os.getcwd()\n",
    "            urllib.request.urlretrieve(url, fname)\n",
    "    \n",
    "#initial data uploading get merge csv  \n",
    "    allFiles = glob.glob(cwd1 + \"/*.csv\")\n",
    "    frame = pd.DataFrame([])\n",
    "    for file_ in allFiles:\n",
    "        df = pd.read_csv(file_,index_col=False, header=0)\n",
    "        frame = frame.append(df)\n",
    "    initialfile = \"PA_\" + '{:%d%m%y}'.format(d) + \"_WBAN_14737.csv\"\n",
    "    frame.to_csv(initialfile, index=False)\n",
    "    #upload initial data\n",
    "    data1 = open(initialfile, 'rb')\n",
    "    s3.Bucket('team7pa_assignment1').put_object(Key=initialfile, Body=data1)\n",
    "    logging.info('Bucket empty: Initial data uploaded')    \n",
    "   \n",
    "    \n",
    "else:   \n",
    "\n",
    "    os.chdir(cwd)\n",
    "    d = dt.date.today()\n",
    "    print(d)\n",
    "    #upload latest data\n",
    "    with open('config.json') as json_data_file:\n",
    "        data = json.load(json_data_file)\n",
    "    url = data['link']\n",
    "    os.chdir(p2)\n",
    "    #get data from config file\n",
    "    urllib.request.urlretrieve(url, 'configfiledata.csv')\n",
    "    logging.info('Data downloaded fron config file path')\n",
    "\n",
    "    df2 = pd.read_csv('configfiledata.csv',index_col=False, header=0,dtype=object)\n",
    "    #download latest file from bucket\n",
    "\n",
    "    b = list(bucket.objects.all())\n",
    "    l = [(k, k.last_modified) for k in b]\n",
    "    l1 = [k for k, v in sorted(l, key=lambda p: p[1], reverse=True)]\n",
    "    key_to_download = l1[0].key\n",
    "\n",
    "    s3.Bucket('team7pa_assignment1').download_file(key_to_download, key_to_download)\n",
    "    df1 = pd.read_csv(key_to_download,index_col=False, header=0,dtype=object)\n",
    "    logging.info('Latest Data From bucket downloaded')\n",
    "    df3 = df1.append(df2)\n",
    "\n",
    "\n",
    "    #upload latest data\n",
    "    newfile = 'PA1_' +'{:%d%m%y}'.format(d) +'_WBAN_14737.csv'\n",
    "    df3.to_csv(newfile, index=False)\n",
    "    key = newfile\n",
    "    objs = list(bucket.objects.filter(Prefix=key))\n",
    "    if len(objs) > 0 and objs[0].key == key:\n",
    "        print(\"File already exists in your bucket!!\")\n",
    "        logging.error('File already exists in your bucket!!Please remove duplicate file.')\n",
    "    else:\n",
    "        data2 = open(newfile, 'rb')\n",
    "        s3.Bucket('team7pa_assignment1').put_object(Key=newfile, Body=data2)\n",
    "        logging.info('New file uploaded')\n",
    "os.chdir(cwd)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
